{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of dynamics learning of SIS on BA networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show an example of dynamics learning of SIS dynamics on Barabasi-Albert networks. We first start by gathering the configuration of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: Support for setting the 'text.latex.preamble' or 'pgf.preamble' rcParam to a list of strings is deprecated since 3.3 and will be removed two minor releases later; set it to a single string instead.\n",
      "  self[key] = other[key]\n"
     ]
    }
   ],
   "source": [
    "from dynalearn.config import ExperimentConfig\n",
    "\n",
    "config = ExperimentConfig.default(\n",
    "    \"example-sis-cave3-net\", \n",
    "    \"sis\", \n",
    "    \"mod_net\", \n",
    "    path_to_data=\"./examples/data\", \n",
    "    path_to_summary=\"./examples/summaries\", \n",
    "    path_to_best=\"./examples/best\", \n",
    "    seed=0\n",
    ")\n",
    "config.metrics.names = (\"TrueLTPMetrics\",\"GNNLTPMetrics\",\"MLELTPMetrics\")\n",
    "config.train_details.num_samples = 1000\n",
    "config.train_details.epochs = 10\n",
    "config.dataset.use_groundtruth = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the experiment from this configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from dynalearn.experiments import Experiment\n",
    "exp = Experiment(config, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run the experiment. We must perform certain tasks before the experiment is completed: 1) we generate the training and validation datasets, 2) we train the model using these datasets and finally 3) we compute the transition probabilities computed by the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Experiment example-sis-cave3-net---\n",
      "Current time: 2021-11-03 13:59:34\n",
      "\n",
      "---Config---\n",
      "name: example-sis-cave3-net\n",
      "path_to_data: ./examples/data/example-sis-cave3-net\n",
      "path_to_best: ./examples/best/example-sis-cave3-net.pt\n",
      "path_to_summary: ./examples/summaries\n",
      "dynamics:\n",
      "\tname: SIS\n",
      "\tinfection: 0.04\n",
      "\trecovery: 0.08\n",
      "\tinit_param: None\n",
      "\tis_weighted: False\n",
      "\tis_multiplex: False\n",
      "\tlag: 1\n",
      "\tlagstep: 1\n",
      "\n",
      "networks:\n",
      "\tname: ModuleNetworkGenerator\n",
      "\tnum_nodes: 1000\n",
      "\tm: 2\n",
      "\tcliques: 2\n",
      "\tcliq_size: 500\n",
      "\n",
      "model:\n",
      "\tname: GNNSEDynamics\n",
      "\tgnn_name: DynamicsGATConv\n",
      "\ttype: linear\n",
      "\tnum_states: 2\n",
      "\toptimizer:\n",
      "\t\tname: RAdam\n",
      "\t\tlr: 0.001\n",
      "\t\tweight_decay: 0.0001\n",
      "\t\tbetas: (0.9, 0.999)\n",
      "\t\teps: 1e-08\n",
      "\t\tamsgrad: False\n",
      "\n",
      "\tin_activation: relu\n",
      "\tgnn_activation: relu\n",
      "\tout_activation: relu\n",
      "\tin_channels: [32, 32]\n",
      "\tgnn_channels: 32\n",
      "\tout_channels: [32, 32]\n",
      "\theads: 2\n",
      "\tconcat: True\n",
      "\tbias: True\n",
      "\tself_attention: True\n",
      "\tis_weighted: False\n",
      "\tis_multiplex: False\n",
      "\tlag: 1\n",
      "\tlagstep: 1\n",
      "\tnetwork_layers: None\n",
      "\tin_size: 1\n",
      "\tout_size: 2\n",
      "\tout_act: softmax\n",
      "\tnode_channels: [0]\n",
      "\tnum_params: 8810\n",
      "\n",
      "dataset:\n",
      "\tname: DiscreteStateWeightDataset\n",
      "\tmodes: ['main']\n",
      "\tbias: 0\n",
      "\treplace: True\n",
      "\tuse_groundtruth: True\n",
      "\tuse_strength: True\n",
      "\tcompounded: True\n",
      "\n",
      "train_details:\n",
      "\tval_fraction: 0.01\n",
      "\tval_bias: 0.8\n",
      "\tepochs: 10\n",
      "\tbatch_size: 1\n",
      "\tnum_networks: 1\n",
      "\tnum_samples: 1000\n",
      "\tresampling: 2\n",
      "\tmaxlag: 1\n",
      "\tresample_when_dead: True\n",
      "\n",
      "metrics:\n",
      "\tnames: ('TrueLTPMetrics', 'GNNLTPMetrics', 'MLELTPMetrics')\n",
      "\tltp:\n",
      "\t\tmax_num_sample: 1000\n",
      "\t\tmax_num_points: -1\n",
      "\n",
      "\tprediciton:\n",
      "\t\tmax_num_points: 10000.0\n",
      "\n",
      "\tstatistics:\n",
      "\t\tmax_num_points: 10000\n",
      "\t\tmaxlag: 1\n",
      "\n",
      "\tstationary:\n",
      "\t\tadaptive: True\n",
      "\t\tnum_nodes: 1000\n",
      "\t\tinit_param: {'absorbing': array([0.999, 0.001])}\n",
      "\t\tsampler: SteadyStateSampler\n",
      "\t\tburn: 1\n",
      "\t\tT: 1000\n",
      "\t\ttol: 500\n",
      "\t\tnum_samples: 5\n",
      "\t\tstatistics: MeanVarStatistics\n",
      "\t\tinit_epsilon: 0.001\n",
      "\t\tparameters: {'absorbing': array([0.1       , 0.24081633, 0.38163265, 0.52244898, 0.66326531,\n",
      "       0.80408163, 0.94489796, 1.08571429, 1.22653061, 1.36734694,\n",
      "       1.50816327, 1.64897959, 1.78979592, 1.93061224, 2.07142857,\n",
      "       2.2122449 , 2.35306122, 2.49387755, 2.63469388, 2.7755102 ,\n",
      "       2.91632653, 3.05714286, 3.19795918, 3.33877551, 3.47959184,\n",
      "       3.62040816, 3.76122449, 3.90204082, 4.04285714, 4.18367347,\n",
      "       4.3244898 , 4.46530612, 4.60612245, 4.74693878, 4.8877551 ,\n",
      "       5.02857143, 5.16938776, 5.31020408, 5.45102041, 5.59183673,\n",
      "       5.73265306, 5.87346939, 6.01428571, 6.15510204, 6.29591837,\n",
      "       6.43673469, 6.57755102, 6.71836735, 6.85918367, 7.        ])}\n",
      "\n",
      "\tattention:\n",
      "\t\tmax_num_points: 100\n",
      "\n",
      "\n",
      "train_metrics: ['jensenshannon', 'model_entropy']\n",
      "callbacks:\n",
      "\tnames: ['ModelCheckpoint', 'StepLR']\n",
      "\tstep_size: 20\n",
      "\tgamma: 0.5\n",
      "\tpath_to_best: ./examples/best/example-sis-cave3-net.pt\n",
      "\n",
      "seed: 0\n",
      "\n",
      "\n",
      "---Generating data---\n",
      "Generating training set\n",
      "Computing weights\n",
      "\n",
      "---Partitioning val-data---\n",
      "Fraction of partitionned samples: 0.0099\n",
      "\n",
      "---Training model---\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jalp/Git/dyna_mine/code-dynalearn/dynalearn/nn/optimizers/radam.py:112: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
      "  p_data_fp32.add_(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_64473/2056608792.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generate_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"partition_val_dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compute_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Git/dyna_mine/code-dynalearn/dynalearn/experiments/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tasks)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tasks__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/Git/dyna_mine/code-dynalearn/dynalearn/experiments/experiment.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, save, restore_best)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n---Training model---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         self.model.nn.fit(\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_details\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/dyna_mine/code-dynalearn/dynalearn/nn/models/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, epochs, batch_size, learning_rate, val_dataset, metrics, callbacks, loggers, verbose)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             self._do_epoch_(\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             )\n",
      "\u001b[0;32m~/Git/dyna_mine/code-dynalearn/dynalearn/nn/models/model.py\u001b[0m in \u001b[0;36m_do_epoch_\u001b[0;34m(self, dataset, batch_size, callbacks, verbose)\u001b[0m\n\u001b[1;32m    110\u001b[0m             }\n\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dyna/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dyna/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp.run([\"generate_data\", \"partition_val_dataset\", \"train_model\", \"compute_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from dynalearn.experiments import LTPMetrics\n",
    "from dynalearn.util.display import *\n",
    "transitions = [(0, 1), (1, 0)]\n",
    "colors = {\n",
    "    \"true\": [color_pale[\"blue\"], color_pale[\"red\"]],\n",
    "    \"gnn\": [color_dark[\"blue\"], color_dark[\"red\"]],\n",
    "    \"mle\": [color_dark[\"blue\"], color_dark[\"red\"]],\n",
    "}\n",
    "linestyles = {\n",
    "    \"true\": [\"-\", \"-\"],\n",
    "    \"gnn\": [\"--\", \"--\"],\n",
    "    \"mle\": [\"None\", \"None\"],\n",
    "}\n",
    "markers = {\n",
    "    \"true\": [\"None\", \"None\"],\n",
    "    \"gnn\": [\"None\", \"None\"],\n",
    "    \"mle\": [\"o\", \"^\"],\n",
    "}\n",
    "\n",
    "def plot_ltp(experiment, ax):\n",
    "    summary = experiment.metrics[\"TrueLTPMetrics\"].data[\"summaries\"]\n",
    "    true_ltp = experiment.metrics[\"TrueLTPMetrics\"].data[\"ltp\"]\n",
    "    gnn_ltp = experiment.metrics[\"GNNLTPMetrics\"].data[\"ltp\"]\n",
    "    mle_ltp = experiment.metrics[\"MLELTPMetrics\"].data[\"ltp\"]\n",
    "    agg = lambda ltp, in_s, out_s: LTPMetrics.aggregate(\n",
    "            ltp, summary, \n",
    "            in_state=in_s, \n",
    "            out_state=out_s,\n",
    "            axis=1, \n",
    "            reduce=\"mean\", \n",
    "            err_reduce=\"percentile\"\n",
    "        )\n",
    "    x_min, x_max = -np.inf, np.inf\n",
    "    for i, (in_s, out_s) in enumerate(transitions):\n",
    "        x, y, yl, yh = agg(true_ltp, in_s, out_s)\n",
    "        ax.plot(\n",
    "            x, y, color=colors[\"true\"][i], linestyle=linestyles[\"true\"][i],marker=markers[\"true\"][i],linewidth=3\n",
    "        )\n",
    "        ax.fill_between(x, yl, yh, color=colors[\"true\"][i], alpha=0.3)\n",
    "        \n",
    "        x, y, yl, yh = agg(gnn_ltp, in_s, out_s)\n",
    "        ax.plot(\n",
    "            x, y, color=colors[\"gnn\"][i], linestyle=linestyles[\"gnn\"][i],marker=markers[\"gnn\"][i],linewidth=3\n",
    "        )\n",
    "        ax.fill_between(x, yl, yh, color=colors[\"gnn\"][i], alpha=0.3)\n",
    "        \n",
    "        x, y, yl, yh = agg(mle_ltp, in_s, out_s)\n",
    "        yerr = np.concatenate([np.expand_dims(y-yl,0), np.expand_dims(yh-y,0)], axis=0)\n",
    "        ax.errorbar(\n",
    "            x, \n",
    "            y, \n",
    "            yerr=yerr,\n",
    "            color=colors[\"mle\"][i], \n",
    "            linestyle=linestyles[\"mle\"][i], \n",
    "            marker=markers[\"mle\"][i], \n",
    "            alpha=0.3\n",
    "        )\n",
    "#         ax.plot(\n",
    "#             x, y, color=colors[\"mle\"][i], linestyle=linestyles[\"mle\"][i], marker=markers[\"mle\"][i], alpha=0.5\n",
    "#         )\n",
    "#         ax.fill_between(x, yl, yh, color=colors[\"mle\"][i], alpha=0.3)\n",
    "        \n",
    "        if x.min() > x_min:\n",
    "            x_min = x.min()\n",
    "        if x.max() < x_max:\n",
    "            x_max = x.max()\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    return ax\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "\n",
    "plot_ltp(exp, ax)\n",
    "ax.set_xlabel(\"Number of infected neighbors\", fontsize=18)\n",
    "ax.set_ylabel(\"Transition probability\", fontsize=18)\n",
    "handles = []\n",
    "\n",
    "handles.append(Line2D([-1], [-1], linestyle=\"-\", marker=\"None\", linewidth=3,\n",
    "                     color=color_pale[\"grey\"], \n",
    "                     label=r\"True\")\n",
    "             )\n",
    "handles.append(Line2D([-1], [-1], linestyle=\"--\", marker=\"None\", linewidth=3,\n",
    "                     color=color_dark[\"grey\"], \n",
    "                     label=r\"GNN\")\n",
    "             )\n",
    "handles.append((Line2D([-1], [-1], linestyle=\"None\", marker=\"o\", markersize=5, markeredgewidth=1,\n",
    "                      markeredgecolor='k', color=color_dark[\"grey\"], alpha=0.3),\n",
    "                Line2D([-1], [-1], linestyle=\"None\", marker=\"^\", markersize=5, markeredgewidth=1,\n",
    "                      markeredgecolor='k', color=color_dark[\"grey\"], alpha=0.3))\n",
    "             )\n",
    "handles.append(Line2D([-1], [-1], linestyle=\"None\", marker=\"s\", markersize=12,\n",
    "                     color=color_pale[\"blue\"])\n",
    "             )\n",
    "handles.append(Line2D([-1], [-1], linestyle=\"None\", marker=\"s\", markersize=12,\n",
    "                     color=color_pale[\"red\"])\n",
    "             )\n",
    "ax.legend(handles=handles, \n",
    "             labels=[r\"GT\", r\"GNN\", r\"MLE\", \"Infection\", \"Recovery\"],\n",
    "             handler_map={tuple: HandlerTuple(ndivide=None)},\n",
    "             loc=\"upper right\", fancybox=True, fontsize=14, framealpha=0.75, ncol=1\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
